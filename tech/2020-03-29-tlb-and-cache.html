<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Ashwin Nanjappa">
  <title>Code Yarns â€“ TLB and cache</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="../styles.css">
  <!-- RSS feed -->
  <link rel="alternate" type="application/rss+xml" href="https://codeyarns.com/tech/rss.xml" />
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-143311697-1">
  </script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-143311697-1');
  </script>
</head>

<body>

<div class="contentbox">
<div class="header">
    <a href=".." class="header">Code Yarns â€ğŸ‘¨â€ğŸ’»</a>
  </div>
  <div class="header">
    <a class="header2" href="https://codeyarns.com/tech/">Tech Blog</a> â– <a class="header2" href="https://codeyarns.com/personal/">Personal Blog</a>
  </div>
  <div class="header">
      <script async src="https://cse.google.com/cse.js?cx=69d6be64abfa91ed2"> </script>
      <div class="gcse-search"></div>
</div>
</div>

<br />

<div class="contentbox">
<header>
<h1 class="title">TLB and cache</h1>
<p class="date">ğŸ“… 2020-Mar-29 â¬© âœï¸ Ashwin Nanjappa â¬© ğŸ·ï¸ <a href='index.html#cache'>cache</a>, <a href='index.html#tlb'>tlb</a> â¬© ğŸ“š <a href="index.html">Archive</a></p>
</header>
<p>My mental model of how TLB and cache are organized and used in modern processors:</p>
<p>Binary code in programs of modern computers only use <strong>virtual addresses</strong>. Addresses are necessary to load instructions (for example, at the address pointed to by the program counter (PC)) or load data (for example, at an offset from the base address of an array in the program). <strong>Address translation</strong> is the process of converting a virtual address in the processâ€™s virtual memory to a physical address in main memory (RAM).</p>
<p><strong>Page tables</strong> hold the mappings from virtual page numbers to page frame numbers. Thus they can be used to map virtual addresses to physical addresses. Page tables can be large and are themselves organized as a tree with multiple levels, where each node is a page and the leaf nodes hold the mappings. Page tables are themselves stored in main memory or might need to be demand-paged into main memory from disk.</p>
<p>Since accessing main memory for address translation is slow, the <strong>translation lookaside buffer (TLB)</strong> is used as a cache for address translation. Similarly, since accessing main memory to load instructions or data is slow, the <strong>cache</strong> (as it is generally called) is used. In modern processors, both TLBs and caches might have multiple levels and might be split for instruction and data.</p>
<p>As an example, a modern processor might have a 3-level cache hierarchy. There might be separate <strong>L1 instruction cache</strong> (i-cache) and <strong>L1 data cache</strong> (d-cache) per core. And then larger L2 and L3 caches, which hold both instructions and data, shared across all the cores.</p>
<p>What is less well known is that the TLB might also be split up in modern processors. For example, a <strong>L1 instruction TLB</strong> and a <strong>L1 data TLB</strong>, followed by a L2 TLB that handles both instruction and data addresses. Another design might just have a L1 TLB and L2 TLB, both of them handling both instruction and data addresses.</p>
<p>Keeping the above in mind, here is how such a modern processor might read instructions or data from main memory:</p>
<figure>
<img src="2020-03-29-tlb-cache.png" alt="" /><figcaption>Â </figcaption>
</figure>
<ul>
<li>There is a virtual address in the program or a register that points to instructions or data that is needed.</li>
<li>The CPU tries to use the L1 and L2 TLBs for translating the virtual address to a physical address. If there is a miss in both L1 and L2 TLBs, then the translation is done by going to the page tables. This might be an order of magnitude slower than TLB.</li>
<li>If the portion of the page table needed is not in main memory, then that needs to be loaded from disk to main memory and then used for translation. This might be orders of magnitude slower than reading from main memory.</li>
<li>The physical address obtained by translation is used on the L1, L2 and L3 caches to get the instructions or data. If there is a miss in the cache hierarchy, then the instruction or data needs to be loaded from main memory.</li>
<li>If there is a page miss, i.e., the page is not in main memory then it has to be loaded from disk. This will be orders of magnitude slower.</li>
</ul>
<p><strong>References</strong>:</p>
<ul>
<li>Appendix B: Review of memory hierarchy from the â€œComputer Architecture A Quantitative Approach (5 Ed)â€ book.</li>
<li>Cortex-A15 Technical Reference Manual</li>
</ul>
</div>

<br />

<div class="contentbox">

<div style="text-align: center">
Â© 2023 Ashwin Nanjappa
â€¢
All writing under <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA</a> license
â€¢
<a href="https://mastodon.social/@codeyarns">ğŸ˜ Mastodon</a>
â€¢
<a href="mailto:codeyarns@gmail.com" style="text-decoration: none; font-size: x-large;">ğŸ“§ Email</a>
</div>
</div>

</body>
</html>
