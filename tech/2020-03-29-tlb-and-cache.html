<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Ashwin Nanjappa">
  <title>Code Yarns â€“ TLB and cache</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="../styles.css">
  <!-- RSS feed -->
  <link rel="alternate" type="application/rss+xml" href="https://codeyarns.com/tech/rss.xml" />
</head>

<body>

<div class="contentbox">
<!-- BEGIN before body -->

<!-- Website title -->
<div class="header">
    <a href=".." class="header">Code Yarns â€ğŸ‘¨â€ğŸ’»</a>
</div>

<!-- Blog links -->
<div class="header">
    <a class="header2" href="https://codeyarns.com/tech/">Tech Blog</a> â– <a class="header2" href="https://codeyarns.com/personal/">Personal Blog</a>
</div>

<!-- Search box -->
<br />
<link href="/pagefind/pagefind-ui.css" rel="stylesheet">
<script src="/pagefind/pagefind-ui.js"></script>
<div id="search"></div>
<script>
    window.addEventListener('DOMContentLoaded', (event) => {
        new PagefindUI({ element: "#search", showSubResults: true });
    });
</script>

<!-- END before body -->
</div>

<br />

<div class="contentbox">
<header>
<h1 class="title">TLB and cache</h1>
<p class="date">ğŸ“… 2020-Mar-29 â¬© âœï¸ Ashwin Nanjappa â¬© ğŸ·ï¸ <a href='index.html#cache'>cache</a>, <a href='index.html#tlb'>tlb</a> â¬© ğŸ“š <a href="index.html">Archive</a></p>
</header>
<p>My mental model of how TLB and cache are organized and used in modern
processors:</p>
<p>Binary code in programs of modern computers only use <strong>virtual
addresses</strong>. Addresses are necessary to load instructions (for
example, at the address pointed to by the program counter (PC)) or load
data (for example, at an offset from the base address of an array in the
program). <strong>Address translation</strong> is the process of
converting a virtual address in the processâ€™s virtual memory to a
physical address in main memory (RAM).</p>
<p><strong>Page tables</strong> hold the mappings from virtual page
numbers to page frame numbers. Thus they can be used to map virtual
addresses to physical addresses. Page tables can be large and are
themselves organized as a tree with multiple levels, where each node is
a page and the leaf nodes hold the mappings. Page tables are themselves
stored in main memory or might need to be demand-paged into main memory
from disk.</p>
<p>Since accessing main memory for address translation is slow, the
<strong>translation lookaside buffer (TLB)</strong> is used as a cache
for address translation. Similarly, since accessing main memory to load
instructions or data is slow, the <strong>cache</strong> (as it is
generally called) is used. In modern processors, both TLBs and caches
might have multiple levels and might be split for instruction and
data.</p>
<p>As an example, a modern processor might have a 3-level cache
hierarchy. There might be separate <strong>L1 instruction cache</strong>
(i-cache) and <strong>L1 data cache</strong> (d-cache) per core. And
then larger L2 and L3 caches, which hold both instructions and data,
shared across all the cores.</p>
<p>What is less well known is that the TLB might also be split up in
modern processors. For example, a <strong>L1 instruction TLB</strong>
and a <strong>L1 data TLB</strong>, followed by a L2 TLB that handles
both instruction and data addresses. Another design might just have a L1
TLB and L2 TLB, both of them handling both instruction and data
addresses.</p>
<p>Keeping the above in mind, here is how such a modern processor might
read instructions or data from main memory:</p>
<figure>
<img src="2020-03-29-tlb-cache.png" alt="Â " />
<figcaption aria-hidden="true">Â </figcaption>
</figure>
<ul>
<li>There is a virtual address in the program or a register that points
to instructions or data that is needed.</li>
<li>The CPU tries to use the L1 and L2 TLBs for translating the virtual
address to a physical address. If there is a miss in both L1 and L2
TLBs, then the translation is done by going to the page tables. This
might be an order of magnitude slower than TLB.</li>
<li>If the portion of the page table needed is not in main memory, then
that needs to be loaded from disk to main memory and then used for
translation. This might be orders of magnitude slower than reading from
main memory.</li>
<li>The physical address obtained by translation is used on the L1, L2
and L3 caches to get the instructions or data. If there is a miss in the
cache hierarchy, then the instruction or data needs to be loaded from
main memory.</li>
<li>If there is a page miss, i.e., the page is not in main memory then
it has to be loaded from disk. This will be orders of magnitude
slower.</li>
</ul>
<p><strong>References</strong>:</p>
<ul>
<li>Appendix B: Review of memory hierarchy from the â€œComputer
Architecture A Quantitative Approach (5 Ed)â€ book.</li>
<li>Cortex-A15 Technical Reference Manual</li>
</ul>
</div>

<br />

<div class="contentbox">

<div style="text-align: center">
Â© 2026 Ashwin Nanjappa
â€¢
All writing under <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA</a> license
â€¢
<a href="https://mastodon.social/@codeyarns">ğŸ˜ Mastodon</a>
â€¢
<a href="https://bsky.app/profile/codeyarns.bsky.social">ğŸ¦‹ Bluesky</a>
â€¢
<a href="mailto:codeyarns@gmail.com">ğŸ“§ Email</a>
</div>
</div>

</body>
</html>
