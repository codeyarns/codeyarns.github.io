<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Ashwin Nanjappa">
  <title>Code Yarns â€“ CUDA: Occupancy Calculator</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="../styles.css">
  <!-- RSS feed -->
  <link rel="alternate" type="application/rss+xml" href="https://codeyarns.github.io/tech/rss.xml" />
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-143311697-1">
  </script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-143311697-1');
  </script>
  <!-- Google Site Search -->
  <script async src="https://cse.google.com/cse.js?cx=003521915278168649297:cryrlg7hahe">
  </script>
</head>
<body>
<table style="width: 100%;">
    <tr>
        <td>
            <a href=".." class="header">Code Yarns &#128187;</a>
        </td>
        <td>
            <div class="gcse-search"></div>
        </td>
    </tr>
</table>
<hr />
<header>
<h1 class="title">CUDA: Occupancy Calculator</h1>
<p class="date">(First posted on: 2011-06-27 06:51:57+00:00)</p>
</header>
<p>The <strong>CUDA Occupancy Calculator</strong> is an Excel spreadsheet that ships with the CUDA Toolkit. It can be used to determine if the number of threads per block being used to launch a kernel is optimal. This spreadsheet can be found at <code>%ProgramData%\NVIDIA Corporation\GPU SDK\C\tools</code></p>
<p>The spreadsheet requires 4 inputs from you specific to the kernel you are analyzing:</p>
<ol type="1">
<li><p>The compute capability of the CUDA device</p></li>
<li><p>Threads per block you are using for the kernel</p></li>
<li><p>Registers per thread for the kernel</p></li>
<li><p>Shared memory per block</p></li>
</ol>
<p>You already know (1) and (2) since you are the author of the kernel. (3) and (4) can be found by compiling the code with the option <code>--ptxas-options=-v</code>. This information can be found in the Output window of Visual Studio during compilation. Another alternative is to run the CUDA program with the <strong>Compute Visual Profiler</strong> and this information can be found in the <strong>Profiler Output</strong> sheet.</p>
<p>Once the above 4 numbers are entered, the 3 charts on the spreadsheet update to show the position of your kernel on them. The 3 charts deal with the parameters threads per block, registers per block and shared memory respectively. Look for the red triangle on the chart whose parameter you have the flexibility to change.</p>
<p><a href="http://codeyarns.files.wordpress.com/2011/06/20110627-cuda-occupancy.png"><img src="http://codeyarns.files.wordpress.com/2011/06/20110627-cuda-occupancy.png" /></a></p>
<p>For example, say for a given kernel I have no say in the number of registers and shared memory it uses. However, I have the ability to change the number of threads per block it launches with. Assume that I am currently using 200 threads per block for this kernel. For this case, I look at Chart 1 (Varying Block Size), and check if the red triangle is on any of the global maxima of the curve. If it is not, I look at the threads per block that will put this kernel at the global maxima and try my kernel with that (say 256). In most cases, my CUDA program should execute a bit faster due to this change since the occupancy of the GPU by the threads of this kernel has been improved.</p>
<p><strong>Tried with</strong>: CUDA 4.0</p>
<hr />
<p><a href="rss.xml">RSS</a> - <a href="mailto:codeyarns@gmail.com">Contact</a></p>
</body>
</html>
