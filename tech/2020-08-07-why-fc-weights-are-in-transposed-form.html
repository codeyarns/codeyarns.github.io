<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Ashwin Nanjappa">
  <title>Code Yarns â€“ Why FC weights are in transposed form</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="../styles.css">
  <!-- RSS feed -->
  <link rel="alternate" type="application/rss+xml" href="https://codeyarns.com/tech/rss.xml" />
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-143311697-1">
  </script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-143311697-1');
  </script>
</head>

<body>

<div class="contentbox">
<div class="header">
    <a href=".." class="header">Code Yarns â€ğŸ‘¨â€ğŸ’»</a>
  </div>
  <div class="header">
    <a class="header2" href="https://codeyarns.com/tech/">Tech Blog</a> â– <a class="header2" href="https://codeyarns.com/personal/">Personal Blog</a>
  </div>
  <div class="header">
      <script async src="https://cse.google.com/cse.js?cx=69d6be64abfa91ed2"> </script>
      <div class="gcse-search"></div>
</div>
</div>

<br />

<div class="contentbox">
<header>
<h1 class="title">Why FC weights are in transposed form</h1>
<p class="date">ğŸ“… 2020-Aug-07 â¬© âœï¸ Ashwin Nanjappa â¬© ğŸ·ï¸ <a href='index.html#fc'>fc</a> â¬© ğŸ“š <a href="index.html">Archive</a></p>
</header>
<p>The torch <a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html"><strong>nn.linear</strong></a> operator is used to implement what is traditionally called the <strong>fully connected</strong> (FC) layer in neural networks. Looking at the nn.linear documentation I noticed that though the weights matrix is used as <code>(in_features, out_features)</code> in the FC, it is stored as its transpose <code>(out_features, in_features)</code>. Why is that?</p>
<p>The consensus seems to be that:</p>
<ul>
<li>During matrix multiplication, the weights matrix is read column-by-column, which is typically not as efficient as reading row-by-row. So, it is stored in the transposed form.</li>
<li>Another reason seems to be that FC is typically mapped down to a BLAS GEMM routine. And in BLAS GEMM, transposes are cheap.</li>
</ul>
<h2 id="references">References</h2>
<ul>
<li><a href="https://discuss.pytorch.org/t/why-does-the-linear-module-seems-to-do-unnecessary-transposing/6277" class="uri">https://discuss.pytorch.org/t/why-does-the-linear-module-seems-to-do-unnecessary-transposing/6277</a></li>
</ul>
</div>

<br />

<div class="contentbox">

<div style="text-align: center">
Â© 2024 Ashwin Nanjappa
â€¢
All writing under <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA</a> license
â€¢
<a href="https://mastodon.social/@codeyarns">ğŸ˜ Mastodon</a>
â€¢
<a href="mailto:codeyarns@gmail.com">ğŸ“§ Email</a>
</div>
</div>

</body>
</html>
